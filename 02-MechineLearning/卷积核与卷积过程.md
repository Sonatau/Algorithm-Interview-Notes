## 空洞卷积

### 定义

空洞卷积(Dilated Convolution)也叫做膨胀卷积、扩张卷积，最初的提出是为了解决图像分割在用下采样（池化、卷积）增加感受野时带来的特征图缩小，后再上采样回去时造成的精度上的损失。

空洞卷积通过引入了一个扩张率Dilation rate的超参数，该参数定义了卷积核处理数据时各值的间距。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2dpZi80bE4xWE9ac2hmZU1ISUlZZFJ5SWljdm5VUEh5c29kRWlhOW41akppYWliZWZOMmliOGhHMzJQaWE4aWNwMVhLeUpORkVqVWhwYkZMYWh5QmNQUWg3WEdkQ3dvUlEvNjQw?x-oss-process=image/format,png)

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2dpZi80bE4xWE9ac2hmZU1ISUlZZFJ5SWljdm5VUEh5c29kRWlhVWFiejdQTk00VWxNNGNZQzBZR1NkazhFbmVxcVZ2cFNiTkhnSnoxZm9FWTc2S3oxOWljelJQZy82NDA?x-oss-process=image/format,png)

### 扩张率

![](https://tva1.sinaimg.cn/large/008i3skNly1gxerkgm9svj30o5086dgp.jpg)

在增加感受野的同时保持特征图的尺寸不变,从而代替下采样和上采样，通过调整扩张率得到不同的感受野不大小：
a. 是普通的卷积过程(dilation rate = 1),卷积后的感受野为3
b. 是dilation rate = 2的空洞卷积,卷积后的感受野为5
c. 是dilation rate = 3的空洞卷积,卷积后的感受野为8

如下图所示，**一个扩张率为2的3×3卷积核，感受野与5×5的卷积核相同，而且仅需要9个参数**

![img](https://img-blog.csdnimg.cn/20190409145225514.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMwMTU5MDE1,size_16,color_FFFFFF,t_70)

空洞卷积是在常规卷积核中填充0，用来扩大感受野，且进行计算时，空洞卷积中实际只有非零的元素起了作用。假设以一个变量a来衡量空洞卷积的扩张系数，则加入空洞之后的实际卷积核尺寸与原始卷积核尺寸之间的关系：
$$
K = k + (k - 1)(a-1)
$$
后面那项表示，红色数字之间共有多少个0

### 空洞卷积的作用

1. 扩大感受野：在deep net中为了增加感受野且降低计算量，总要进行降采样(pooling或s2/conv)，这样虽然可以增加感受野，但空间分辨率降低了。为了能不丢失分辨率，且仍然扩大感受野，可以使用空洞卷积

2. 捕获多尺度上下文信息：当多个带有不同dilation rate的空洞卷积核叠加时，不同的感受野会带来多尺度信息。

### 缺陷及如何解决

- **局部信息丢失**：由于空洞卷积的计算方式类似于棋盘格式，某一层得到的卷积结果，来自上一层的独立的集合，没有相互依赖，因此该层的卷积结果之间没有相关性，即局部信息丢失。
- **远距离获取的信息没有相关性**：由于空洞卷积稀疏的采样输入信号，使得远距离卷积得到的信息之间没有相关性，影响分类结果。

## 感受野的计算

感受野指的是卷积神经网络每一层输出的特征图上每个像素点映射回输入图像上的区域的大小。

**神经元感受野的范围越大表示其接触到的原始图像范围就越大，也就意味着它能学习更为全局，语义层次更高的特征信息，相反，范围越小则表示其所包含的特征越趋向局部和细节**。

因此感受野的范围可以用来大致判断每一层的抽象层次，并且我们可以很明显地知道网络越深，神经元的感受野越大。

**卷积层的感受野大小与其之前层的卷积核尺寸和步长有关**，与padding无关。

下面我们给出感受野大小的计算公式：

![Image](https://mmbiz.qpic.cn/mmbiz_png/4lN1XOZshffB4xA4Eibvupg8FxOiaHpZK5mZFYLcpA88CZh86S2oicYvcptgPgteEOJWNic2NJwdXkqnblqV9m3R7Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)其中RF_l+1为当前特征图对应的感受野大小，也就是我们要计算的目标感受野，RF_l为上一层特征图对应的感受野大小，f_l+1为当前卷积层卷积核大小，最后一项连乘项则表示之前卷积层的步长乘积。

根据感受野的计算公式我们来看上图中两次卷积的感受野计算过程：

原始输入size为`5 * 5`，第一层卷积核为`3 * 3`，输入步长为1，输入层初始化感受野为`1*1`，根据公式计算可得第一层卷积后的特征图对应的输入空间的感受野大小为：`1 + (3-1)*1=3`。

第一层卷积输出特征图的感受野size为3，第二层卷积核size为3，卷积步长为2，则第二层的的感受野size计算为`3+(3-1)*2*1=7`。

## 反卷积

定义：将图像尺寸恢复到原来的尺寸（由小分辨率到大分辨率）

![img](https://pic1.zhimg.com/v2-2b6e5c02e3dc2c60cc3fbb2d5fba88fc_b.jpg)

### 输出尺寸计算

**第一步**：对输入的特征图做**插值**，在原先高宽方向的每两个相邻中间插上**（Stride−1）**列0。

如下图所示，原来的尺寸为3*3，因为stride=2,则是在相邻行（列）之间插入(2-1)行（列）0

插入后的尺寸为为：`height = height+(height-1) * (stride-1)`,这里也就是`h=3+(2-1)(3-1)=5`,即插值过后的 特征图为`5 * 5`。

![img](https://pic3.zhimg.com/v2-72794700c3f33187d34ce3d72c570856_b.png)

**第二步**：求新的卷积核设置

新卷积核的**kernel_new不变为3，stride_new恒为1，padding_new =(kernel_size - padding - 1) = 1**

**第三步**：用新的卷积核在新的特征图上做常规的卷积，得到的结果就是逆卷积的结果。

即在5 * 5的特征图上执行nn.conv(1,3,3,stride = 1,padding = 1),最后输出的特征图尺寸为：(5-3+2 * 1)/1+1=5

### 棋盘格效应

当核尺寸不能被步长整除的时候，反卷积会有不均匀的重叠。

当stride为2的时候，kernel是奇数就会出现网格：

![](https://tva1.sinaimg.cn/large/008i3skNly1gxfqht2bh0j312i0iy3zx.jpg)

如果Kernel为偶数就不会有这种情况：

![](https://tva1.sinaimg.cn/large/008i3skNly1gxfqj7ao3bj312e0jkwfx.jpg)

而如果是多层堆叠反卷积的话而参数配置又不当，那么棋盘状的现象就会层层传递：

![](https://tva1.sinaimg.cn/large/008i3skNly1gxfqjr00mmj311u0e8my8.jpg)

### Pytorch实现

```python
batch_size = 1
in_channel = 1
height = 4
width = 4

data_shape = (batch_size, in_channel, height, width)
conv_input = torch.ones(data_shape)

out_channel = 1
kernel_size = 3
weight_shape = (in_channel, out_channel, kernel_size, kernel_size)
conv_weight = torch.ones(weight_shape)

# kernel_size无法被整除 容易出现棋盘效应
conv_trans = nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=kernel_size, stride=2, padding=1)
conv_trans.weight = torch.nn.Parameter(conv_weight)

y = conv_trans.forward(conv_input)
print(y)
```

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gxfrtg0tsdj30x80b6gnq.jpg" style="height:150px" />

如果把kernel_size修改为4，这个效应会消失

```python
conv_trans = nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=4, stride=2, padding=1)
conv_trans.weight = torch.nn.Parameter(conv_weight)

y = conv_trans.forward(conv_input)
print(y)
```

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gxfs0cl5qbj30yc0coaco.jpg" style="height:150px" />