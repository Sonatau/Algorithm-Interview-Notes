## 分类指标

以下指标用于二分类问题，如果是多分类的问题，也可以使用1:M的方法转变成二分类进行计算。

### 混淆矩阵 Confusion Matrix

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gwyjq0tj34j30xi0dsmy5.jpg" height="200px" />

### 准确率 - accuracy

全局预测正确的样本数占所有样本数的比例，计算公式如下：
$$
Acc = \frac{TP + TN}{ALL}
$$
缺点：在binary classification且正反例不平衡的情况下，计算准确率没有意义。

假设在测试集里，有100个sample，99个反例，只有1个正例。如果模型对任意一个sample都预测为反例，Acc是 正确的个数／总个数 = 99/100 = 99%，但显然这样的预测是不合理的。

### 查准率 Precision

所有预测为正样本的集合中预测正确的比例：
$$
Precision = \frac{TP}{TP + FP}
$$

### 查全率 Recall

所有正样本中预测正确的比例，即正样本的准确率。
$$
Recall = \frac{TP}{TP + FN}
$$
如果你的模型很贪婪，想要覆盖更多的sample，那么它就更有可能犯错。在这种情况下，你会有很高的recall，但是较低的precision。

如果你的模型很保守，只对它很sure的sample作出预测，那么你的precision会很高，但是recall会相对低。

### F1值

综合精确率和召回率指标，相当于调和均值。计算公式如下：
$$
F1 = \frac{2 * Precision * Recall }{Precision + Recall}
$$
缺点：如果两个模型，一个precision特别高，recall特别低，另一个recall特别高，precision特别低的时候，f1-score可能是差不多的，因此也不能基于此来作出选择。

当类别不平衡时，可以使用PR曲线和ROC曲线进行模型评估。

### ROC曲线
以TPR(True Positive Rate，真正率，等于召回率)为纵轴：所有正例中被预测为正例的概率。
$$
TPR = \frac{TP}{P} = \frac{TP}{TP + FN}
$$

FPR(False Positive Rate，假正率，不是真正的正)为横轴：所有负例中被预测为正例的概率。
$$
FPR = \frac{FP}{N} =\frac{FP}{FP + TN}
$$

当一个样本被分类器判为正例，若其本身是正例，则TPR增加；

若其本身是负例，则FPR增加，因此ROC曲线可以看作是随着阈值的不断移动，所有样本中正例与负例之间的“对抗”。

曲线越靠近左上角，意味着越多的正例优先于负例，模型的整体表现也就越好。

#### 作图

在不同的分类阈值 (threshold) 设定下分别以TPR和FPR为纵、横轴作图。

1. 假设有P个正例，N个反例。
2. 分类器对所有样本的正负例进行预测，将得到一个probability score，**对所有样本按预测概率排序**。
3. 设定一个threshold，大于该值为正例，小于为负例。
4. 将分类阈值设为最大，即把所有样本均预测为反例，对应图上的点为 (0,0)。
5. 将分类阈值依次设为每个样本的预测概率，即依次将每个样本划分为正例，可以画出坐标轴中新的点
6. 所有样本点的TPR和FPR值，用线段相连，如下图黄线所示。

<img src="https://pic3.zhimg.com/80/v2-70f8ba09d21ca845a1ec0c107e41212e_1440w.jpg?source=1940ef5c" height="400px" />

- AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。

- 0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值（比如0.5）的话，能有预测价值。

- AUC = 0.5，跟随机猜测一样（例如：抛硬币猜正反面），模型没有预测价值。

- AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。

#### AUC (Area Under the Curve)

AUC需要计算折线下方的面积，根据下图所示，其实相当于是求解梯形的面积。

![](https://tva1.sinaimg.cn/large/008i3skNly1gwzt3c2fs4j31gq0u0q5s.jpg)

从所有正例中随机选取一个样本A，再从所有负例中随机选取一个样本B，分类器将A判为正例的概率比将B判为正例的概率大的可能性。

可以看到位于蓝色虚线上方的点(如图中的A点)被认为好于随机猜测。

在这样的点上TPR总大于FPR，意为正例被判为正例的概率大于负例被判为正例的概率。

<img src="https://pic3.zhimg.com/80/v2-2dc9d2148aefd4bf6ff879b3b85837e6_1440w.jpg" alt="img" height="300px" />


#### 优势

1. 注意TPR用到的TP和FN同属P列，FPR用到的FP和TN同属N列，所以即使P或N的整体数量发生了改变，也不会影响到另一列。也就是说，**即使正负例变得不平衡，ROC曲线也不会产生大的变化**，而像Precision使用的TP和FP就分属两列，则易受类别分布改变的影响。

2. 在类别不平衡的背景下，**负例的数目众多致使FPR的增长不明显，导致ROC曲线呈现一个过分乐观的效果估计**。当负例N的数量远超正例P时，FP的大幅增长只能换来FPR的微小改变。结果是虽然大量负例被错判成正例，在ROC曲线上却无法直观地看出来。

    举个例子，假设一个数据集有正例20，负例10000，开始时有20个负例被错判，FPR=0.002 ，接着又有20个负例错判， FPR=0.004 ，在ROC曲线上这个变化是很细微的。而与此同时Precision则从原来的0.5下降到了0.33，在PR曲线上将会是一个大幅下降。

### PR曲线

以查全率为横轴，查准率为纵轴，所以称为P(Precision 纵)R(Recall 横)曲线。

<img src="https://pic1.zhimg.com/80/v2-6f09575f1a32692274177e7d2da55066_1440w.jpg?source=1940ef5c" height="250px" />

曲线下的面积(AUC)越大，或者说曲线更接近右上角（precision=1， recall=1），那么模型就越理想，越好。

**类别不平衡问题中，PR曲线则因为Precision的存在会不断显现FP的影响。**

### 适用场景

地震的时候，模型应该将每一次地震都预测到，查全率需要尽可能高，做出错误预测也没有关系。

人脸识别的时候，模型应该尽可能提高查准率，不然就会导致把陌生人放进去。

**ROC与PR的选择**

1. 如果想要评估在**相同**的类别分布下正例的预测情况，则宜选PR曲线。
2. 类别不平衡问题中，ROC曲线通常会给出一个乐观的效果估计，所以大部分时候还是PR曲线更好。
3. ROC曲线由于兼顾正例与负例，所以适用于评估分类器的整体性能，相比而言PR曲线完全聚焦于正例。

### 对数损失

在正负例不平衡的情况下，对数损失没有意义。

![img](https://upload-images.jianshu.io/upload_images/3007211-b8cb1dd10c07eb9c.png?imageMogr2/auto-orient/strip|imageView2/2/w/498)

## 回归指标

模型训练的时候，通过比较这些指标

### 均方误差 - Mean Squared Error

观测值与真值偏差的平方和与观测次数的比值：

$$
MSE = \frac{1}{m}\sum_{i=1}^{m}(f_i-y_i)^2
$$

### 均方根误差 - Root Mean Squared Error

它的意义在于开个根号后，误差的结果就与数据是一个级别的，可以更好地来描述数据。标准误差对一组测量中的特大或特小误差反映非常敏感

$$
RMSE =\sqrt{\frac{1}{m}\sum_{i=1}^{m}(f_i-y_i)^2}
$$

### 平均绝对误差 - Mean Absolute Error

平均绝对误差是绝对误差的平均值，能更好地反映预测值误差的实际情况。

$$
MAE = \frac{1}{m}\sum_{i=1}^{m}|f_i-y_i|
$$

### 代码实现

#### Acc、Pre、Recall实现

```python
import numpy as np
from numpy.random import rand, seed, shuffle, normal
import matplotlib.pyplot as plt


# 模型准确率计算
def get_acc(y, y_hat):
    return sum(yi == yi_hat for yi, yi_hat in zip(y, y_hat)) / len(y)


# 查准率 TP / (TP + NP)
def get_precision(y, y_hat):
    true_positive = sum(yi and yi_hat for yi, yi_hat in zip(y, y_hat))
    predicted_positive = sum(y_hat)
    return true_positive / predicted_positive


# 查全率 TP / (TP + FN) = TPR
def get_recall(y, y_hat):
    true_positive = sum(yi and yi_hat for yi, yi_hat in zip(y, y_hat))
    actual_positive = sum(y)  # 真正的正例
    return true_positive / actual_positive


# 假正率：所有负例样本中被预测为正类的概率 FP / N = FP / (TN + FP)
def get_fpr(y, y_hat):
    false_positive = sum(yi == 0 and yi_hat == 1 for yi,
                         yi_hat in zip(y, y_hat))
    actual_negative = len(y) - sum(y)
    return false_positive / actual_negative
```

#### ROC实现

**示例1**：

```python
def get_roc(y, y_hat_prob):
    thresholds = sorted(set(y_hat_prob), reverse=True)  # 阈值选择
    ret = [[0, 0]]  # 第一次全部预测为负例 为原始点[0,0]

    # 大于阈值则为正例
    for threshold in thresholds:
        y_hat = [int(yi_hat_prob >= threshold) for yi_hat_prob in y_hat_prob]
        ret.append([get_recall(y, y_hat), get_fpr(y, y_hat)])

    return ret


def get_auc(y, y_hat_prob):
    roc = iter(get_roc(y, y_hat_prob))
    tpr_pre, fpr_pre = next(roc)
    auc = 0
    for tpr, fpr in roc:
        auc += (tpr + tpr_pre) * (fpr - fpr_pre) / 2  # 梯形求面积
        tpr_pre = tpr
        fpr_pre = fpr

    return auc
```

然后生成1000个实际值，其中500个值为1,500个值为0，顺序被随机打乱。再随机生成1000个实际值作为预测结果。

```python
seed(100)
y = np.array([0, 1] * 500)
shuffle(y)

seed(20)
y_pred = rand(1000)
points = np.array(get_roc(y, y_pred))
plt.plot(points[:, 1], points[:, 0])
plt.show()
```

计算出ROC曲线的数据点，并绘制ROC曲线。

不难看出这条ROC曲线的AUC值约等于0.5，而预测值都是我们随机生成的，也就印证了AUC为0.5时模型没有预测能力的说法。

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gwztluvwysj30ye0u0ta9.jpg" height="400px" />

**示例2**：**对于正例有着较强预测能力的ROC曲线**

阈值为0.5时，我们让正例的预测值有95%的可能性是正确预测，负例的预测值有70%的可能性是正确预测：

比如yi = 1，那么预测值有95%的可能性是[0.5, 1]之间的随机数。如果yi = 0，那么预测值有70%的可能性是[0, 0.5]之间的随机数。

```python
def power_positive(x):
    if x == 1:
        if rand() > 0.05:
            return rand() / 2 + 0.5
        else:
            return rand() / 2
    else:
        if rand() > 0.3:
            return rand() / 2
        else:
            return rand() / 2 + 0.5
          
y_pred = np.array([power_positive(yi) for yi in y])
points = np.array(get_roc(y, y_pred))
plt.plot(points[:, 1], points[:, 0])
plt.show()
```

计算出ROC曲线的数据点，并绘制ROC曲线。可以看出ROC曲线的形状是偏上的。

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gwzthirj9qj30ye0u0dhc.jpg" height="400px" />

## 参考博客

- https://zhuanlan.zhihu.com/p/34655990
- https://www.jianshu.com/p/ce70c716c9d1
- 🌟https://cloud.tencent.com/developer/article/1379081
